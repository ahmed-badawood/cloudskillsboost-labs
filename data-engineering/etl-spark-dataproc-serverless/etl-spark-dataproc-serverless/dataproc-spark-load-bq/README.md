# Use Dataproc Serverless for Spark to Load BigQuery

## ðŸŽ¯ Objective
Run a **Dataproc Serverless (Spark)** batch that reads **Avro** files from **Cloud Storage** and loads them into **BigQuery**.

## ðŸ§± What this demonstrates
- Serverless Spark batch submission with `gcloud dataproc batches`
- Reading Avro from GCS in PySpark
- Writing to BigQuery via the Spark BigQuery connector
